{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01a7d31b-d1a7-4352-8405-ed1a94a6af80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Fox25\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import spatial\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "input_path = '../test_data/STS.input.images.txt'\n",
    "#input_path = '../test_data/testinput.txt'\n",
    "output_path = './output/STS.output.images.txt'\n",
    "#output_path = './output/testoutput.txt'\n",
    "nltk.download('stopwords')\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "#ファイル入力\n",
    "with open(input_path) as f:\n",
    "    s = f.read()\n",
    "s = s.strip().replace('\\t','\\n').replace('.','')\n",
    "sentences = s.split('\\n')\n",
    "# ps = PorterStemmer()\n",
    "# for i in range(len(sentences)):\n",
    "#     token = sentences[i].split('/n')\n",
    "#     singles = [ps.stem(plural) for plural in token]\n",
    "#     sentences[i] = ' '.join(singles)\n",
    "# print(sentences)\n",
    "    \n",
    "#Vectorizerを設定する。\n",
    "vectorizer = CountVectorizer(lowercase=True,stop_words=stopwords)\n",
    "\n",
    "#語彙の獲得とidfの計算\n",
    "vectorizer.fit(sentences)\n",
    "#tf-idf行列の生成\n",
    "X = vectorizer.transform(sentences)\n",
    "# print(vectorizer.get_feature_names_out())\n",
    "# words = vectorizer.get_feature_names_out()\n",
    "# vec1,vec2 = X.toarray()[0],X.toarray()[1]\n",
    "# cos_sim = 1 - spatial.distance.cosine(vec1,vec2)\n",
    "# print(cos_sim,spatial.distance.cosine(vec1,vec2))\n",
    "\n",
    "# l = 1500\n",
    "l = len(sentences)\n",
    "print(l)\n",
    "\n",
    "#c750個のcos類似度リスト\n",
    "cos_sim_list = []\n",
    "#出力用の文字列\n",
    "output = ''\n",
    "\n",
    "# vecs1 = []\n",
    "# vecs2 = []\n",
    "\n",
    "#それぞれ類似度を求める。\n",
    "for i in range(int(l/2)):\n",
    "    vec1 = X.toarray()[2*i]\n",
    "    #vecs1.append(vec1)\n",
    "    vec2 = X.toarray()[2*i+1]\n",
    "    #vecs2.append(vec2)\n",
    "    #cos距離を用いて類似度を出す。\n",
    "    cos_sim = 1 - spatial.distance.cosine(vec1,vec2)\n",
    "    cos_sim_list.append(cos_sim)\n",
    "    output += str(cos_sim) + '\\n'\n",
    "# cos_sim = cosine_similarity(vecs1,vecs2)\n",
    "with open(output_path,mode='w') as f:\n",
    "    f.write(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
