{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ZFEnbRoFmr3w"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "#文章数の指定\n",
    "N = 10\n",
    "#各文章を単語に分割したリストを得る\n",
    "docs = []\n",
    "for n in range(N):\n",
    "  with open(f'input/{n}.txt',encoding='cp932') as f:\n",
    "    docs.append(f.read().split('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "skdz_gYUp3ux"
   },
   "outputs": [],
   "source": [
    "#各文章のtfを求める\n",
    "tf_list = []\n",
    "for n in range(N):\n",
    "  #ある文章\n",
    "  words = docs[n]\n",
    "  tf = {}\n",
    "  #文章から一単語ずつ持ってくる\n",
    "  for word in words:\n",
    "    if not(word in tf):\n",
    "      tf[word] = 1\n",
    "    else :\n",
    "      tf[word] += 1\n",
    "  tf_list.append(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "vbtiPlVDnqN2"
   },
   "outputs": [],
   "source": [
    "#各文章のdfを求める\n",
    "df_list = []\n",
    "for n in range(N):\n",
    "  #ある文章のtf\n",
    "  tf = tf_list[n]\n",
    "  df = {}\n",
    "  #単語をtfから持ってくることで重複がないことが保証される\n",
    "  for word in tf:\n",
    "    count = 0\n",
    "    for n in range(N):\n",
    "      if(word in tf_list[n]):\n",
    "        #単語が見つかればcountをインクリメントして次の文章へ\n",
    "        count += 1\n",
    "        continue\n",
    "    df[word] = count\n",
    "  df_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "_zFRcqAJTfqu"
   },
   "outputs": [],
   "source": [
    "#各文章のtf-idfを求める\n",
    "tf_idf_list = []\n",
    "for n in range(N):\n",
    "  tf,df = tf_list[n],df_list[n]\n",
    "  tfidf = {}\n",
    "  for word in tf:\n",
    "    val = tf[word] * math.log(10/df[word])\n",
    "    tfidf[word] = val\n",
    "  tf_idf_list.append(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "XjDK1RdQZMvu"
   },
   "outputs": [],
   "source": [
    "#出力のための関数\n",
    "def print_tf_idf(tf_idf:dict):\n",
    "  output = ''\n",
    "  for word in tf_idf:\n",
    "    output += word+'\\t'+str(tf_idf[word])+'\\n'\n",
    "  return output\n",
    "\n",
    "#ファイル出力\n",
    "for n in range(N):\n",
    "  output = print_tf_idf(tf_idf_list[n])\n",
    "  with open(f'output/{n}.txt',mode='w') as f:\n",
    "    f.write(output)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
