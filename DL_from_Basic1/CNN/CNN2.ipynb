{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423eafcb-805c-43a9-9e92-0efe6a736f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.2996618468154004\n",
      "=== epoch:1, train acc:0.239, test acc:0.232 ===\n",
      "train loss:2.296690005074707\n",
      "train loss:2.2912080974620723\n",
      "train loss:2.284710097479397\n",
      "train loss:2.2748663973201215\n",
      "train loss:2.2610098285037035\n",
      "train loss:2.2490822884304444\n",
      "train loss:2.219908187608077\n",
      "train loss:2.196854976287224\n",
      "train loss:2.1605110367033835\n",
      "train loss:2.1292478988655694\n",
      "train loss:2.0849651342729603\n",
      "train loss:2.0227585057038526\n",
      "train loss:1.9556959006871448\n",
      "train loss:1.9212935109180302\n",
      "train loss:1.7856060187662155\n",
      "train loss:1.7553327406767036\n",
      "train loss:1.7896237588794888\n",
      "train loss:1.6236443459126844\n",
      "train loss:1.4791398717085251\n",
      "train loss:1.3915058078467941\n",
      "train loss:1.4399504117510107\n",
      "train loss:1.3345028907683574\n",
      "train loss:1.170321327205844\n",
      "train loss:1.1457875572764236\n",
      "train loss:1.1942352637471958\n",
      "train loss:1.0480420409206672\n",
      "train loss:1.0610088652472631\n",
      "train loss:0.9617027886059026\n",
      "train loss:0.945131596107844\n",
      "train loss:0.9183164924793021\n",
      "train loss:0.6476425299524535\n",
      "train loss:0.7269604151837532\n",
      "train loss:0.7957381758240433\n",
      "train loss:0.6607946887883532\n",
      "train loss:0.6974972761063636\n",
      "train loss:0.5910181563196236\n",
      "train loss:0.8642626669660095\n",
      "train loss:0.6329074316546524\n",
      "train loss:0.5198937400288045\n",
      "train loss:0.5370874349472239\n",
      "train loss:0.4175520357923918\n",
      "train loss:0.5067547912135957\n",
      "train loss:0.6915923206116856\n",
      "train loss:0.8860150281964608\n",
      "train loss:0.6010819059932861\n",
      "train loss:0.6159241721000355\n",
      "train loss:0.5636847623200123\n",
      "train loss:0.5764916162755457\n",
      "train loss:0.514313354420214\n",
      "train loss:0.529912308735855\n",
      "train loss:0.5252058282539721\n",
      "train loss:0.4216772313881672\n",
      "train loss:0.5228245971044594\n",
      "train loss:0.6131283690865817\n",
      "train loss:0.4170239399670359\n",
      "train loss:0.4090977283580355\n",
      "train loss:0.4491723261091481\n",
      "train loss:0.5518698606384969\n",
      "train loss:0.6250661886794239\n",
      "train loss:0.4986601268113569\n",
      "train loss:0.38254988666214457\n",
      "train loss:0.4790616954648563\n",
      "train loss:0.5517265334248994\n",
      "train loss:0.6644072065141028\n",
      "train loss:0.5118504759626138\n",
      "train loss:0.40023682994391757\n",
      "train loss:0.43459239925336385\n",
      "train loss:0.6162024171687119\n",
      "train loss:0.4853098746129349\n",
      "train loss:0.5192912729820541\n",
      "train loss:0.37446921424429214\n",
      "train loss:0.3806875748468451\n",
      "train loss:0.4936006726545474\n",
      "train loss:0.38738512558379523\n",
      "train loss:0.3265765289522079\n",
      "train loss:0.3559359421728082\n",
      "train loss:0.44038417244540473\n",
      "train loss:0.41166085101103\n",
      "train loss:0.249767063027026\n",
      "train loss:0.4312654912003615\n",
      "train loss:0.5405818396643918\n",
      "train loss:0.34365115221256753\n",
      "train loss:0.4373153039472897\n",
      "train loss:0.5776006947615501\n",
      "train loss:0.438381574900026\n",
      "train loss:0.37495237691861705\n",
      "train loss:0.35955679911646093\n",
      "train loss:0.3379486379730354\n",
      "train loss:0.3010077934515759\n",
      "train loss:0.4312149716463962\n",
      "train loss:0.5081220266698446\n",
      "train loss:0.2767590116599304\n",
      "train loss:0.3499135076332619\n",
      "train loss:0.33072523597162984\n",
      "train loss:0.4003810963353836\n",
      "train loss:0.3707009584369756\n",
      "train loss:0.37882936877947027\n",
      "train loss:0.29212146360517804\n",
      "train loss:0.4610834568704951\n",
      "train loss:0.3462442510932238\n",
      "train loss:0.21268248947661259\n",
      "train loss:0.359537561636878\n",
      "train loss:0.39190710712742144\n",
      "train loss:0.47873500896901844\n",
      "train loss:0.4097136063630009\n",
      "train loss:0.4078028017765969\n",
      "train loss:0.45065290489228943\n",
      "train loss:0.2792500628282324\n",
      "train loss:0.20191818424117752\n",
      "train loss:0.4921198345560595\n",
      "train loss:0.33393640376769906\n",
      "train loss:0.540305916111508\n",
      "train loss:0.48104423861617845\n",
      "train loss:0.2395494723693842\n",
      "train loss:0.2870804182201047\n",
      "train loss:0.5355145374386665\n",
      "train loss:0.2978640860827588\n",
      "train loss:0.40547887448846515\n",
      "train loss:0.3909426646345429\n",
      "train loss:0.2927802324561219\n",
      "train loss:0.29744473409453226\n",
      "train loss:0.26616592431896885\n",
      "train loss:0.25763541917050575\n",
      "train loss:0.3078692826418914\n",
      "train loss:0.32619498482516013\n",
      "train loss:0.3170395408480319\n",
      "train loss:0.4834758794625458\n",
      "train loss:0.27469328342002314\n",
      "train loss:0.377361551652489\n",
      "train loss:0.3139925111649438\n",
      "train loss:0.5055971654742284\n",
      "train loss:0.41859362555558327\n",
      "train loss:0.28557649005799507\n",
      "train loss:0.2655260469366293\n",
      "train loss:0.273932844947892\n",
      "train loss:0.3560575758850635\n",
      "train loss:0.2941704400229257\n",
      "train loss:0.48000465823765043\n",
      "train loss:0.4146262653436863\n",
      "train loss:0.37758736922162794\n",
      "train loss:0.3141188835865599\n",
      "train loss:0.356265282768019\n",
      "train loss:0.44376047504557997\n",
      "train loss:0.4565970001604592\n",
      "train loss:0.38047048488558066\n",
      "train loss:0.20612466498179888\n",
      "train loss:0.36336989647936735\n",
      "train loss:0.284913021495114\n",
      "train loss:0.3005473170522374\n",
      "train loss:0.27426097472762584\n",
      "train loss:0.3133437987827504\n",
      "train loss:0.27668786505747645\n",
      "train loss:0.32079616816921247\n",
      "train loss:0.4429799540427987\n",
      "train loss:0.3938428428021497\n",
      "train loss:0.3027446345141687\n",
      "train loss:0.19333497078720774\n",
      "train loss:0.2654375207552859\n",
      "train loss:0.3706303280673973\n",
      "train loss:0.35122829575739106\n",
      "train loss:0.30901352132986903\n",
      "train loss:0.38108379118571084\n",
      "train loss:0.3619186910858603\n",
      "train loss:0.3492228005287952\n",
      "train loss:0.2868615307771341\n",
      "train loss:0.3052541932392561\n",
      "train loss:0.2266714058416224\n",
      "train loss:0.3679497200302189\n",
      "train loss:0.20648650151218625\n",
      "train loss:0.31498649232851256\n",
      "train loss:0.22492804265686372\n",
      "train loss:0.19817646369259267\n",
      "train loss:0.22722281986495957\n",
      "train loss:0.3749198075690218\n",
      "train loss:0.24363451327981103\n",
      "train loss:0.18362688897529136\n",
      "train loss:0.27970566276239417\n",
      "train loss:0.25244890502997597\n",
      "train loss:0.36149063640705614\n",
      "train loss:0.2674014649362679\n",
      "train loss:0.18700355258190193\n",
      "train loss:0.4048031118234922\n",
      "train loss:0.2748215185988615\n",
      "train loss:0.2841806240080489\n",
      "train loss:0.28493941642048415\n",
      "train loss:0.32023990485775833\n",
      "train loss:0.2866404475829322\n",
      "train loss:0.37086215958387464\n",
      "train loss:0.20204501891727858\n",
      "train loss:0.20631374572459416\n",
      "train loss:0.3399848482291081\n",
      "train loss:0.19272019562414797\n",
      "train loss:0.32870310715437895\n",
      "train loss:0.34223291260427563\n",
      "train loss:0.3873196373317509\n",
      "train loss:0.3668287453429697\n",
      "train loss:0.21613814155666322\n",
      "train loss:0.233152949254958\n",
      "train loss:0.27880760324065174\n",
      "train loss:0.32401594001756534\n",
      "train loss:0.2871368013245696\n",
      "train loss:0.2676058717178935\n",
      "train loss:0.24812560720949783\n",
      "train loss:0.2649444476897933\n",
      "train loss:0.2752488008607805\n",
      "train loss:0.5277400272091964\n",
      "train loss:0.26283777243173106\n",
      "train loss:0.22391816927305755\n",
      "train loss:0.24081395759377902\n",
      "train loss:0.2519175409009244\n",
      "train loss:0.34778712103575415\n",
      "train loss:0.24593103662195556\n",
      "train loss:0.1536425410270345\n",
      "train loss:0.28586593604620253\n",
      "train loss:0.314911778060237\n",
      "train loss:0.28249947173168366\n",
      "train loss:0.21163370780552815\n",
      "train loss:0.2898315706887153\n",
      "train loss:0.3255854638651093\n",
      "train loss:0.37483911255545804\n",
      "train loss:0.2556568706071229\n",
      "train loss:0.2154629719606394\n",
      "train loss:0.16062144514147486\n",
      "train loss:0.32821030384757566\n",
      "train loss:0.29610159402754216\n",
      "train loss:0.2147726369574936\n",
      "train loss:0.2663848275924761\n",
      "train loss:0.3113073185649857\n",
      "train loss:0.37244004312760864\n",
      "train loss:0.2382938050181082\n",
      "train loss:0.22677591894552898\n",
      "train loss:0.26480585826186653\n",
      "train loss:0.24041435527702448\n",
      "train loss:0.22052133874910929\n",
      "train loss:0.18532208277925613\n",
      "train loss:0.23837683465781415\n",
      "train loss:0.37055891061290824\n",
      "train loss:0.27642224451443126\n",
      "train loss:0.23241494817049474\n",
      "train loss:0.323334172694949\n",
      "train loss:0.3188278006465312\n",
      "train loss:0.3295423479424154\n",
      "train loss:0.4335106114730551\n",
      "train loss:0.23042914840936932\n",
      "train loss:0.2465427470607717\n",
      "train loss:0.21656633353992524\n",
      "train loss:0.24166466659580507\n",
      "train loss:0.1548902680610631\n",
      "train loss:0.32471521367165296\n",
      "train loss:0.26841240084962886\n",
      "train loss:0.23564152246644604\n",
      "train loss:0.3767700313913883\n",
      "train loss:0.22127419577469434\n",
      "train loss:0.24360008563591617\n",
      "train loss:0.2940947732598649\n",
      "train loss:0.20876765992970234\n",
      "train loss:0.21470345258153492\n",
      "train loss:0.24113242188724432\n",
      "train loss:0.33998099395328324\n",
      "train loss:0.26997759345595895\n",
      "train loss:0.3694064384746877\n",
      "train loss:0.20255469174215793\n",
      "train loss:0.2749281171923225\n",
      "train loss:0.3058255082908792\n",
      "train loss:0.22275745752257897\n",
      "train loss:0.38077868909443424\n",
      "train loss:0.165522394716774\n",
      "train loss:0.22729449217163075\n",
      "train loss:0.18964552522846215\n",
      "train loss:0.15396507936448933\n",
      "train loss:0.2806013837552982\n",
      "train loss:0.32895790294448296\n",
      "train loss:0.3575145765048433\n",
      "train loss:0.2539595516958925\n",
      "train loss:0.2542110999772269\n",
      "train loss:0.11860887374152909\n",
      "train loss:0.1608147925083136\n",
      "train loss:0.13244822170242548\n",
      "train loss:0.3015974660745695\n",
      "train loss:0.1721726355362527\n",
      "train loss:0.27522192584826466\n",
      "train loss:0.3091231342209097\n",
      "train loss:0.33055241680470554\n",
      "train loss:0.13047959159278205\n",
      "train loss:0.21409871825016552\n",
      "train loss:0.24131195582695195\n",
      "train loss:0.27216937282669273\n",
      "train loss:0.23967686378002004\n",
      "train loss:0.14602422180155497\n",
      "train loss:0.20601672383432168\n",
      "train loss:0.29766867562357413\n",
      "train loss:0.20674934829139585\n",
      "train loss:0.3122408315547607\n",
      "train loss:0.2333207124547793\n",
      "train loss:0.31712788586025015\n",
      "train loss:0.24717453055596814\n",
      "train loss:0.32334157605875397\n",
      "train loss:0.16779111892513576\n",
      "train loss:0.1636231927737552\n",
      "train loss:0.259848385913409\n",
      "train loss:0.05965961941014207\n",
      "train loss:0.2931745955390063\n",
      "train loss:0.2828448488500525\n",
      "train loss:0.27149509587926257\n",
      "train loss:0.21407014740794866\n",
      "train loss:0.20973028197982288\n",
      "train loss:0.21007612585882676\n",
      "train loss:0.16397050815434913\n",
      "train loss:0.21645475476666617\n",
      "train loss:0.21235433066335155\n",
      "train loss:0.2001448948782776\n",
      "train loss:0.32836904244761944\n",
      "train loss:0.3066412517180904\n",
      "train loss:0.25326510174391714\n",
      "train loss:0.1495678755933184\n",
      "train loss:0.24023454033212624\n",
      "train loss:0.3116750575379275\n",
      "train loss:0.26602752424707515\n",
      "train loss:0.2647564181434478\n",
      "train loss:0.3042469703552659\n",
      "train loss:0.17192332316917106\n",
      "train loss:0.44244721776727014\n",
      "train loss:0.22213266138783563\n",
      "train loss:0.11041915304934002\n",
      "train loss:0.15580749959293816\n",
      "train loss:0.20622008280007376\n",
      "train loss:0.18946432589894432\n",
      "train loss:0.27154024220402523\n",
      "train loss:0.35476089362616287\n",
      "train loss:0.20638464121409508\n",
      "train loss:0.12004974534462753\n",
      "train loss:0.31321786886120084\n",
      "train loss:0.22197642069873638\n",
      "train loss:0.3416046816841516\n",
      "train loss:0.1912263304292489\n",
      "train loss:0.12331797421827533\n",
      "train loss:0.17223283281582652\n",
      "train loss:0.25815199701954794\n",
      "train loss:0.31453566784783554\n",
      "train loss:0.21082411708370397\n",
      "train loss:0.1795775102066398\n",
      "train loss:0.10589372076869015\n",
      "train loss:0.18829058873388255\n",
      "train loss:0.2833700441819936\n",
      "train loss:0.17594080640571572\n",
      "train loss:0.2918746154698333\n",
      "train loss:0.1665348486353925\n",
      "train loss:0.1393799330706321\n",
      "train loss:0.29890958644223087\n",
      "train loss:0.24385682266600173\n",
      "train loss:0.22633118957659032\n",
      "train loss:0.17481063669389155\n",
      "train loss:0.1391545429210923\n",
      "train loss:0.18558951928402856\n",
      "train loss:0.1273396381701215\n",
      "train loss:0.16188446965028747\n",
      "train loss:0.24753365560123494\n",
      "train loss:0.16154950325052284\n",
      "train loss:0.13756521283026502\n",
      "train loss:0.17353009824806825\n",
      "train loss:0.32215557866457173\n",
      "train loss:0.20456456738624748\n",
      "train loss:0.16797510991071374\n",
      "train loss:0.23221517318287924\n",
      "train loss:0.20597117594505077\n",
      "train loss:0.14026280700945656\n",
      "train loss:0.23126554475326436\n",
      "train loss:0.28206411578632556\n",
      "train loss:0.2884473888069429\n",
      "train loss:0.23413564741804202\n",
      "train loss:0.3724024323072414\n",
      "train loss:0.24514113674581284\n",
      "train loss:0.20065668103609505\n",
      "train loss:0.12833666266822713\n",
      "train loss:0.12930213152709227\n",
      "train loss:0.2081893080577832\n",
      "train loss:0.15923174802047263\n",
      "train loss:0.10925682568997062\n",
      "train loss:0.15393308676301937\n",
      "train loss:0.1497194537380335\n",
      "train loss:0.17458539944559753\n",
      "train loss:0.15413761483414082\n",
      "train loss:0.12857125111562318\n",
      "train loss:0.23654717248009455\n",
      "train loss:0.23635929641025136\n",
      "train loss:0.21707668116808163\n",
      "train loss:0.23188246944215252\n",
      "train loss:0.3833066718245239\n",
      "train loss:0.10650375687840262\n",
      "train loss:0.13428405384469672\n",
      "train loss:0.1821485040058131\n",
      "train loss:0.16031377313296324\n",
      "train loss:0.07387417541525851\n",
      "train loss:0.14853600948489906\n",
      "train loss:0.12310626053175619\n",
      "train loss:0.13074306332152918\n",
      "train loss:0.22523992330203815\n",
      "train loss:0.14858841634667708\n",
      "train loss:0.20759873346930802\n",
      "train loss:0.18428720973590437\n",
      "train loss:0.09287148007110774\n",
      "train loss:0.29169321430480566\n",
      "train loss:0.14769916009479625\n",
      "train loss:0.2119102508815097\n",
      "train loss:0.13708317622614716\n",
      "train loss:0.19365072943511852\n",
      "train loss:0.1957450325924399\n",
      "train loss:0.21310027042634958\n",
      "train loss:0.18382552898371834\n",
      "train loss:0.1436180526710911\n",
      "train loss:0.13074961858868966\n",
      "train loss:0.1280697219869691\n",
      "train loss:0.1556734886477834\n",
      "train loss:0.1960154485025406\n",
      "train loss:0.25947618048980275\n",
      "train loss:0.14675190185155182\n",
      "train loss:0.1063888226380071\n",
      "train loss:0.17690940719980483\n",
      "train loss:0.33824285823252387\n",
      "train loss:0.20190668563953973\n",
      "train loss:0.4222188937176329\n",
      "train loss:0.16314071230715854\n",
      "train loss:0.24796577764380665\n",
      "train loss:0.16973373439175873\n",
      "train loss:0.11984682548976476\n",
      "train loss:0.11849346566619698\n",
      "train loss:0.12661193698824896\n",
      "train loss:0.13109250924907798\n",
      "train loss:0.17789533050954703\n",
      "train loss:0.0954514611903949\n",
      "train loss:0.21435109064707641\n",
      "train loss:0.10648890966113118\n",
      "train loss:0.12642735824374823\n",
      "train loss:0.12589637534290873\n",
      "train loss:0.20352845271815465\n",
      "train loss:0.31528574320635083\n",
      "train loss:0.09527431093443196\n",
      "train loss:0.17480753524162487\n",
      "train loss:0.10397361741956206\n",
      "train loss:0.11499343762670876\n",
      "train loss:0.0817608669683366\n",
      "train loss:0.12101114009208805\n",
      "train loss:0.21595508449653444\n",
      "train loss:0.17829006235283704\n",
      "train loss:0.24411223704194415\n",
      "train loss:0.13963580332825315\n",
      "train loss:0.26455444208852813\n",
      "train loss:0.13597297078407652\n",
      "train loss:0.2785395625546213\n",
      "train loss:0.10699545160417821\n",
      "train loss:0.12379779259549606\n",
      "train loss:0.16630192359554563\n",
      "train loss:0.22135770688268658\n",
      "train loss:0.12290572916830395\n",
      "train loss:0.4412683228636996\n",
      "train loss:0.11209267656258545\n",
      "train loss:0.209408808247427\n",
      "train loss:0.19857046177866752\n",
      "train loss:0.18262225754397549\n",
      "train loss:0.18133100848834566\n",
      "train loss:0.16909488522827978\n",
      "train loss:0.20564993312662116\n",
      "train loss:0.12910870906823937\n",
      "train loss:0.35109788780407286\n",
      "train loss:0.2650108665436203\n",
      "train loss:0.23976812371845174\n",
      "train loss:0.19109271140850148\n",
      "train loss:0.09923871493018298\n",
      "train loss:0.11365877068938307\n",
      "train loss:0.14297347452271397\n",
      "train loss:0.11066186736769472\n",
      "train loss:0.09752114364339215\n",
      "train loss:0.14247763089059837\n",
      "train loss:0.1488560008072797\n",
      "train loss:0.15866192487948835\n",
      "train loss:0.11452802662568777\n",
      "train loss:0.22861670664525324\n",
      "train loss:0.1733357770823267\n",
      "train loss:0.16626877980215155\n",
      "train loss:0.16254677848122207\n",
      "train loss:0.11833238807096177\n",
      "train loss:0.11446243773088041\n",
      "train loss:0.22336082719053532\n",
      "train loss:0.07475826860459325\n",
      "train loss:0.14943779330678533\n",
      "train loss:0.15991481093006255\n",
      "train loss:0.15601361286031565\n",
      "train loss:0.18965274620239708\n",
      "train loss:0.1978214072193969\n",
      "train loss:0.10254751005762763\n",
      "train loss:0.07905165402999498\n",
      "train loss:0.08988467498333104\n",
      "train loss:0.14301647030645326\n",
      "train loss:0.11487744699785499\n",
      "train loss:0.2771855509699504\n",
      "train loss:0.1255318616919724\n",
      "train loss:0.09462176728134626\n",
      "train loss:0.19470620191214677\n",
      "train loss:0.2506063005156194\n",
      "train loss:0.12137339527465478\n",
      "train loss:0.19489786106241547\n",
      "train loss:0.1303417527494386\n",
      "train loss:0.12320867434198421\n",
      "train loss:0.1569469695536281\n",
      "train loss:0.15441651119572908\n",
      "train loss:0.08918990515692193\n",
      "train loss:0.19150429767984195\n",
      "train loss:0.13521429052954953\n",
      "train loss:0.13173183206394495\n",
      "train loss:0.060075283608803466\n",
      "train loss:0.10968624394932217\n",
      "train loss:0.2717917187385601\n",
      "train loss:0.09240418728975537\n",
      "train loss:0.05003916391511711\n",
      "train loss:0.13334971427620826\n",
      "train loss:0.22640530879019122\n",
      "train loss:0.18060035629292492\n",
      "train loss:0.10165683737669537\n",
      "train loss:0.14970989409781674\n",
      "train loss:0.12050565198912802\n",
      "train loss:0.0884430810005504\n",
      "train loss:0.141512834925526\n",
      "train loss:0.12487972700099488\n",
      "train loss:0.11210965371264665\n",
      "train loss:0.14204040147775066\n",
      "train loss:0.18490586778251283\n",
      "train loss:0.1472974133817277\n",
      "train loss:0.20712107324917892\n",
      "train loss:0.19548950252476513\n",
      "train loss:0.2233809584407139\n",
      "train loss:0.08837437560996236\n",
      "train loss:0.17533212744696708\n",
      "train loss:0.16234525093976754\n",
      "train loss:0.07087878002601954\n",
      "train loss:0.22651289924760717\n",
      "train loss:0.13882038514240158\n",
      "train loss:0.14119822213784128\n",
      "train loss:0.158675530856025\n",
      "train loss:0.09875120337938985\n",
      "train loss:0.09133364027877316\n",
      "train loss:0.21962191251913638\n",
      "train loss:0.1016724731925357\n",
      "train loss:0.16704526199210853\n",
      "train loss:0.17741255816291093\n",
      "train loss:0.07692101351404619\n",
      "train loss:0.11254975109042711\n",
      "train loss:0.16037642872128646\n",
      "train loss:0.11236202472577432\n",
      "train loss:0.20694856350735205\n",
      "train loss:0.20569828633736686\n",
      "train loss:0.13942877144954643\n",
      "train loss:0.12341601194077814\n",
      "train loss:0.10675926248495628\n",
      "train loss:0.14513451933120008\n",
      "train loss:0.07928431944110179\n",
      "train loss:0.07303871339164085\n",
      "train loss:0.11802890855800241\n",
      "train loss:0.14920231677268744\n",
      "train loss:0.10288851989072226\n",
      "train loss:0.035167349757792433\n",
      "train loss:0.08442568380730489\n",
      "train loss:0.1737109312498167\n",
      "train loss:0.07549992044376475\n",
      "train loss:0.31950696231038883\n",
      "train loss:0.1644055202605424\n",
      "train loss:0.1334833970344071\n",
      "train loss:0.0754145885448241\n",
      "train loss:0.05706258745518783\n",
      "train loss:0.32136037100584913\n",
      "train loss:0.044505467374719415\n",
      "train loss:0.11217798783826678\n",
      "train loss:0.1128834525390268\n",
      "train loss:0.1348209076663962\n",
      "train loss:0.2111856886842048\n",
      "train loss:0.2378136072527014\n",
      "train loss:0.2437829607893074\n",
      "train loss:0.16506671296463485\n",
      "train loss:0.16302948155474822\n",
      "train loss:0.14613813472669304\n",
      "train loss:0.15524254795585268\n",
      "train loss:0.10461822959214274\n",
      "train loss:0.09310341796767956\n",
      "train loss:0.13101292723003724\n",
      "train loss:0.08703631121940797\n",
      "train loss:0.12367533691401401\n",
      "train loss:0.10349193322730622\n",
      "train loss:0.139595337954042\n",
      "train loss:0.1595834673037573\n",
      "train loss:0.18929391677873666\n",
      "train loss:0.0938725125273984\n",
      "train loss:0.09977086590466323\n",
      "train loss:0.19370630466949312\n",
      "train loss:0.1045361153066826\n",
      "train loss:0.10346636042858531\n",
      "train loss:0.14273383416935212\n",
      "train loss:0.1017036109886174\n",
      "train loss:0.12293060497646945\n",
      "train loss:0.054120354600339635\n",
      "train loss:0.20655888619540183\n",
      "train loss:0.12671892847085872\n",
      "=== epoch:2, train acc:0.957, test acc:0.951 ===\n",
      "train loss:0.1494589732605031\n",
      "train loss:0.07282170659076365\n",
      "train loss:0.16883912353151545\n",
      "train loss:0.06372741111249362\n",
      "train loss:0.15077242633976795\n",
      "train loss:0.19474846987634994\n",
      "train loss:0.25199898244941593\n",
      "train loss:0.13633906732618395\n",
      "train loss:0.15517172406270846\n",
      "train loss:0.14123667466755832\n",
      "train loss:0.07826094535947851\n",
      "train loss:0.07467895468130263\n",
      "train loss:0.11766745148246915\n",
      "train loss:0.11813453205138527\n",
      "train loss:0.19696823393871557\n",
      "train loss:0.11164208578283942\n",
      "train loss:0.14761573485462734\n",
      "train loss:0.09921555096764763\n",
      "train loss:0.08743176598947437\n",
      "train loss:0.12765423803436993\n",
      "train loss:0.12702742579504867\n",
      "train loss:0.0770699716292975\n",
      "train loss:0.16938054746587536\n",
      "train loss:0.13281472703443212\n",
      "train loss:0.15785420538122474\n",
      "train loss:0.0830724468388982\n",
      "train loss:0.16609544814501845\n",
      "train loss:0.12532744656911046\n",
      "train loss:0.1406981593680532\n",
      "train loss:0.15880831035290421\n",
      "train loss:0.1489135244408778\n",
      "train loss:0.14214281805441292\n",
      "train loss:0.06472278456149834\n",
      "train loss:0.11978495215445491\n",
      "train loss:0.13181252876076938\n",
      "train loss:0.13187177199227867\n",
      "train loss:0.16816935733447827\n",
      "train loss:0.09280832103128958\n",
      "train loss:0.07533452272948382\n",
      "train loss:0.13092861471407138\n",
      "train loss:0.11188562230046778\n",
      "train loss:0.08307085681391159\n",
      "train loss:0.11299932001453719\n",
      "train loss:0.0893918740120428\n",
      "train loss:0.13012397930790495\n",
      "train loss:0.1178274316194884\n",
      "train loss:0.13360957478142738\n",
      "train loss:0.1088643871618164\n",
      "train loss:0.11184658016030044\n",
      "train loss:0.08533683740185508\n",
      "train loss:0.0641435762991691\n",
      "train loss:0.0801727715707393\n",
      "train loss:0.031217080022022108\n",
      "train loss:0.04923082645513649\n",
      "train loss:0.10936159871275283\n",
      "train loss:0.2746545897946054\n",
      "train loss:0.1134583930900402\n",
      "train loss:0.13239185155537736\n",
      "train loss:0.08255267214669225\n",
      "train loss:0.07293601476533534\n",
      "train loss:0.08687409048298812\n",
      "train loss:0.13610389218159957\n",
      "train loss:0.08667855441312218\n",
      "train loss:0.08139107697051606\n",
      "train loss:0.09118347151563358\n",
      "train loss:0.16895332463630353\n",
      "train loss:0.08028770581115376\n",
      "train loss:0.11687242907638398\n",
      "train loss:0.051852666144154895\n",
      "train loss:0.0977334927484742\n",
      "train loss:0.04604929189930317\n",
      "train loss:0.07850475863844295\n",
      "train loss:0.24593498839281\n",
      "train loss:0.03774508300104353\n",
      "train loss:0.08131770175862277\n",
      "train loss:0.07595365839012849\n",
      "train loss:0.17857589334640708\n",
      "train loss:0.11921856615008677\n",
      "train loss:0.08098330016365647\n",
      "train loss:0.07628247632527481\n",
      "train loss:0.1391251079183652\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 親ディレクトリのファイルをインポートするための設定\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "from simple_convnet import SimpleConvNet\n",
    "from common.trainer import Trainer\n",
    "\n",
    "# データの読み込み\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n",
    "\n",
    "# 処理に時間のかかる場合はデータを削減 \n",
    "#x_train, t_train = x_train[:5000], t_train[:5000]\n",
    "#x_test, t_test = x_test[:1000], t_test[:1000]\n",
    "\n",
    "max_epochs = 20\n",
    "\n",
    "network = SimpleConvNet(input_dim=(1,28,28), \n",
    "                        conv_param = {'filter_num': 30, 'filter_size': 5, 'pad': 0, 'stride': 1},\n",
    "                        hidden_size=100, output_size=10, weight_init_std=0.01)\n",
    "                        \n",
    "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
    "                  epochs=max_epochs, mini_batch_size=100,\n",
    "                  optimizer='Adam', optimizer_param={'lr': 0.001},\n",
    "                  evaluate_sample_num_per_epoch=1000)\n",
    "trainer.train()\n",
    "\n",
    "# パラメータの保存\n",
    "network.save_params(\"params.pkl\")\n",
    "print(\"Saved Network Parameters!\")\n",
    "\n",
    "# グラフの描画\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(max_epochs)\n",
    "plt.plot(x, trainer.train_acc_list, marker='o', label='train', markevery=2)\n",
    "plt.plot(x, trainer.test_acc_list, marker='s', label='test', markevery=2)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6753213a-fb89-4686-a357-0ed9b1c9f076",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e2beec-8bd5-44fa-bddb-70f05a61076c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
